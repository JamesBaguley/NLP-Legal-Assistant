{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "838e2c35-d895-42c9-9d64-992999ed78af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "import os\n",
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "243fc406-d1c7-4504-af20-0ebbb27ea306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys available:  ['OPENAI_KEY']\n"
     ]
    }
   ],
   "source": [
    "%run keys.ipynb\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e28ae543-9f0b-4714-9dd0-969d98efc7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://leginfo.legislature.ca.gov/faces/codes_displayText.xhtml?lawCode=CIV&division=4.&title=&part=5.&chapter=10.&article=3.\n",
      "Code: DIVISION 4. GENERAL PROVISIONS [3274 - 9566]( Heading of Division 4 amended by Stats. 1988, Ch. 160, Sec. 16. )PART 5. Common Interest Developments [4000 - 6150]( Part 5 added by Stats. 2012, Ch. 180, Sec. 2. )CHAPTER 10\n",
      "Text: (a) “Alternative dispute resolution” means mediation, arbitration, conciliation, or other nonjudicial procedure that involves a neutral party in the decisionmaking process. The form of alternative dispute resolution chosen pursuant to this article may be binding or nonbinding, with the voluntary consent of the parties.(b) “Enforcement action” means a civil action or proceeding, other than a cross-complaint, for any of the following purposes:(1) Enforcement of this act.(2) Enforcement of the Nonprofit Mutual Benefit Corporation Law (Part 3 (commencing with Section 7110) of Division 2 of Title 1 of the Corporations Code).(3) Enforcement of the governing documents.(Added by Stats. 2012, Ch. 180, Sec. 2. (AB 805) Effective January 1, 2013. Operative January 1, 2014, by Sec. 3 of Ch. 180.)5930.(a) An association or a member may not file an enforcement action in the superior court unless the parties have endeavored to submit their dispute to alternative dispute resolution pursuant to this article.(b) This section applies only to an enforcement action that is solely for declaratory, injunctive, or writ relief, or for that relief in conjunction with a claim for monetary damages not in excess\n"
     ]
    }
   ],
   "source": [
    "# Load the file\n",
    "file_path = \"scraped_data.txt\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "entries = raw_text.split(\"\\n\\n\")\n",
    "\n",
    "# Function to clean text content\n",
    "def clean_text_content(text):\n",
    "    # Remove JavaScript artifacts and unwanted phrases\n",
    "    patterns_to_remove = [\n",
    "        r\"Up\\^Add To My Favorites\",  \n",
    "        r\"Add To My Favorites\",      \n",
    "        r\"Up\",                       \n",
    "        r\"\\[.*?\\]\",                  \n",
    "        r\"Code Text.*?:\",            \n",
    "        r\"DIVISION\\s*\\d+.*?CHAPTER\\s*\\d+\",  \n",
    "        r\"https?://\\S+\",             \n",
    "    ]\n",
    "    for pattern in patterns_to_remove:\n",
    "        text = re.sub(pattern, \"\", text)\n",
    "    \n",
    "    # Remove excessive whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "# Updated function to extract entry details\n",
    "def extract_entry_details(entry):\n",
    "    # Define regular expressions to capture URL and code\n",
    "    url_pattern = r\"URL:\\s*(https?://\\S+)\"\n",
    "    code_pattern = r\"DIVISION\\s*(\\d+).*(CHAPTER\\s*\\d+)\"\n",
    "    text_pattern = r\"Text Content:\\s*(.*)\"\n",
    "\n",
    "    url = re.search(url_pattern, entry)\n",
    "    code = re.search(code_pattern, entry)\n",
    "    text = re.search(text_pattern, entry)\n",
    "\n",
    "    # Extract values or set None if not found\n",
    "    url = url.group(1) if url else None\n",
    "    code = code.group(0) if code else None\n",
    "    text = clean_text_content(text.group(1)) if text else None\n",
    "\n",
    "    return {\"url\": url, \"code\": code, \"text\": text}\n",
    "\n",
    "# Function to detect index-like entries\n",
    "def is_index_like(text):\n",
    "    # Common patterns in index-like entries\n",
    "    index_keywords = [\"CHAPTER\", \"PART\", \"ARTICLE\", \"DIVISION\"]\n",
    "    # Count occurrences of index keywords\n",
    "    keyword_count = sum(text.count(keyword) for keyword in index_keywords)\n",
    "    # Count the number of lines with enumerations\n",
    "    enumeration_count = len(re.findall(r\"\\d+\\.\", text))  # Matches \"1.\", \"2.\", etc.\n",
    "    # Count non-alphabetic characters\n",
    "    non_alpha_ratio = sum(1 for c in text if not c.isalpha()) / max(1, len(text))\n",
    "    \n",
    "    # Thresholds for detecting index-like content\n",
    "    if keyword_count > 5 or enumeration_count > 5 or non_alpha_ratio > 0.5:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Apply the filter during document extraction\n",
    "documents = [extract_entry_details(entry) for entry in entries]\n",
    "\n",
    "# Remove entries with missing text content\n",
    "documents = [doc for doc in documents if doc[\"text\"]]\n",
    "\n",
    "# Filter out index-like documents\n",
    "filtered_documents = [doc for doc in documents if not is_index_like(doc[\"text\"])]\n",
    "\n",
    "# Create a Hugging Face Dataset with the filtered data\n",
    "corpus = Dataset.from_dict({\n",
    "    \"url\": [doc[\"url\"] for doc in filtered_documents],\n",
    "    \"code\": [doc[\"code\"] for doc in filtered_documents],\n",
    "    \"text\": [doc[\"text\"] for doc in filtered_documents]\n",
    "})\n",
    "\n",
    "print(f\"URL: {corpus['url'][100]}\")\n",
    "print(f\"Code: {corpus['code'][100]}\")\n",
    "print(f\"Text: {corpus['text'][100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65139038-986a-44b3-bac0-6fb76182c139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jbags\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load embedding model\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(\"cuda\")  # Move to GPU\n",
    "\n",
    "# Embedding function with GPU support\n",
    "def encode(texts, batch_size=8):\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(\"cuda\")  # Move to GPU\n",
    "        with torch.no_grad():\n",
    "            embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "        all_embeddings.append(embeddings.cpu().numpy())  # Move back to CPU for FAISS\n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "# Embed the corpus text\n",
    "corpus_embeddings = encode(corpus[\"text\"])\n",
    "\n",
    "# Create a FAISS index with GPU support\n",
    "res = faiss.StandardGpuResources()  # Initialize FAISS GPU resources\n",
    "index_flat = faiss.IndexFlatL2(corpus_embeddings.shape[1])  # L2 distance index\n",
    "index = faiss.index_cpu_to_gpu(res, 0, index_flat)  # Move index to GPU\n",
    "index.add(corpus_embeddings)  # Add embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3152c0c9-60d3-488e-9f73-d15490669913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text, user_context=None, max_summary_tokens=1024):\n",
    "    # Prepare the base prompt\n",
    "    prompt = f\"Summarize the following text:\\n\\n{text}\"\n",
    "    \n",
    "    # Incorporate user context if provided\n",
    "    if user_context:\n",
    "        prompt = f\"Considering the following user context:\\n{user_context}\\n\\n{prompt}\"\n",
    "\n",
    "    # Use openai.ChatCompletion.create() for summarization\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",  # or \"gpt-4-32k\" for handling larger inputs\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        max_tokens=max_summary_tokens,  # Limit the number of tokens in the summary\n",
    "        temperature=0.5,  # Control the randomness (set to 0 for deterministic output)\n",
    "        top_p=1.0,  # Top probability sampling\n",
    "        n=1,  # Single response\n",
    "    )\n",
    "\n",
    "    # Extract the summary from the response\n",
    "    summary = response['choices'][0]['message']['content'].strip()\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8561f866-5aed-4406-a015-cd0cdc57db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated retrieval function to return full document details (url, code, division, text)\n",
    "def retrieve(query, top_k=3):\n",
    "    query_embedding = encode([query])\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    \n",
    "    # Fetch the corresponding document details\n",
    "    results = []\n",
    "    for i in indices[0]:\n",
    "        doc = {\n",
    "            \"url\": corpus[\"url\"][i],\n",
    "            \"code\": corpus[\"code\"][i],\n",
    "            \"text\": corpus[\"text\"][i]\n",
    "        }\n",
    "        results.append(doc)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00f8590d-e2cd-4e87-a357-13cd5ad43b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load generative model\n",
    "gen_model_name = \"google/flan-t5-large\"\n",
    "gen_tokenizer = AutoTokenizer.from_pretrained(gen_model_name)\n",
    "gen_model = AutoModelForSeq2SeqLM.from_pretrained(gen_model_name).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "448f21d0-895c-49e9-9967-508ac39b78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the response generation with more detailed context and parameters like temperature\n",
    "def generate_response(query, documents, max_length=500, temperature=0.3, top_p=0.9):\n",
    "    context = \" \".join([doc[\"text\"] for doc in documents]) # Extract \"text\" from each document\n",
    "    input_text = f\"Query: {query}\\nContext: {context}\\nAnswer with details:\"\n",
    "    inputs = gen_tokenizer(input_text, return_tensors=\"pt\", truncation=True).to(\"cuda\")  # Move to GPU\n",
    "    with torch.no_grad():\n",
    "        outputs = gen_model.generate(\n",
    "            **inputs, \n",
    "            max_length=max_length,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p\n",
    "        )\n",
    "    return gen_tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a57c7bd5-c7d6-4ba2-bb5a-443882eda4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline(query, min_required_docs=1):\n",
    "    print(\"Starting RAG pipeline...\")\n",
    "    \n",
    "    # Retrieve relevant documents\n",
    "    documents = retrieve(query)\n",
    "    print(f\"Retrieved {len(documents)} documents.\")\n",
    "    \n",
    "    # Check if we retrieved enough documents\n",
    "    if len(documents) < min_required_docs:\n",
    "        print(\"Not enough relevant documents found.\")\n",
    "        return [{\"response\": \"Sorry, I don't have the ability to answer that question based on the available information.\"}]\n",
    "    \n",
    "    # Generate a summary for each document\n",
    "    summaries = []\n",
    "    for doc in documents:\n",
    "        summary = summarize_text(doc[\"text\"])\n",
    "        summaries.append({\n",
    "            \"url\": doc[\"url\"],\n",
    "            \"code\": doc[\"code\"],\n",
    "            \"summary\": summary\n",
    "        })  \n",
    "    \n",
    "    print(\"Generated summaries.\")\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6df7e6d7-4752-4182-a6a0-47b977e4ac43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RAG pipeline...\n",
      "Retrieved 3 documents.\n",
      "Generated summaries.\n",
      "URL: https://leginfo.legislature.ca.gov/faces/codes_displayText.xhtml?lawCode=HSC&division=104.&title=&part=15.&chapter=2.&article=5.\n",
      "Code: DIVISION 104. ENVIRONMENTAL HEALTH [106500 - 119406]( Division 104 added by Stats. 1995, Ch. 415, Sec. 6. )PART 15. MISCELLANEOUS REQUIREMENTS [118375 - 119406]( Part 15 added by Stats. 1995, Ch. 415, Sec. 6. )CHAPTER 2\n",
      "Summary: The Health and Safety Code (HSC) requires all single-user toilet facilities in any business, public place, or state or local government agency to be identified as all-gender facilities. The signage must comply with Title 24 of the California Code of Regulations, and the facility should be designated for use by one occupant at a time or for family or assisted use. During inspections, officials may check for compliance with this rule. The term \"single-user toilet facility\" refers to a toilet facility with no more than one occupant.\n",
      "--------------------------------------------------------------------------------\n",
      "URL: https://leginfo.legislature.ca.gov/faces/codes_displayText.xhtml?lawCode=HSC&division=104.&title=&part=15.&chapter=2.&article=6.\n",
      "Code: DIVISION 104. ENVIRONMENTAL HEALTH [106500 - 119406]( Division 104 added by Stats. 1995, Ch. 415, Sec. 6. )PART 15. MISCELLANEOUS REQUIREMENTS [118375 - 119406]( Part 15 added by Stats. 1995, Ch. 415, Sec. 6. )CHAPTER 2\n",
      "Summary: The text defines two terms: \"Department\" refers to the State Department of Public Health, and \"Eligible medical condition\" includes diseases like Crohn's disease, ulcerative colitis, and other conditions that require immediate access to a toilet facility. The State Department of Public Health is tasked with implementing this article in consultation with the Department of Consumer Affairs. The implementation of this article should not conflict with or limit rights under the Americans with Disabilities Act of 1990, the Unruh Civil Rights Act, or any other civil rights law. The text also refers to an employee toilet facility accessed according to this article.\n",
      "--------------------------------------------------------------------------------\n",
      "URL: https://leginfo.legislature.ca.gov/faces/codes_displayText.xhtml?lawCode=HSC&division=104.&title=&part=7.&chapter=13.&article=2.\n",
      "Code: DIVISION 104. ENVIRONMENTAL HEALTH [106500 - 119406]( Division 104 added by Stats. 1995, Ch. 415, Sec. 6. )PART 7. CALIFORNIA RETAIL FOOD CODE [113700 - 114437]( Part 7 repealed and added by Stats. 2006, Ch. 23, Sec. 2. )CHAPTER 13\n",
      "Summary: The Health and Safety Code - HSC, Chapter 13, Article 2, added in 2006, outlines the role of enforcement officers in ensuring compliance with health and safety regulations. These officers are authorized to enforce the regulations at any food facility, cottage food operation, or suspected food-related facility during its hours of operation. They can enter and inspect these locations, issue citations, and gather evidence such as samples, photographs, etc. This also applies to vehicles transporting food to or from a retail food facility when stationary at places like agricultural inspection stations, border crossings, or any food facility under their jurisdiction.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example query and user context\n",
    "query = \"what is the law around restrooms in restaurants?\"\n",
    "user_context = \"A layman unfamiliar with California law looking for legal advice.\"\n",
    "\n",
    "# Use the RAG pipeline\n",
    "summaries = rag_pipeline(query)\n",
    "\n",
    "# Display the retrieved documents and summaries\n",
    "if isinstance(summaries[0], dict) and 'response' in summaries[0]:\n",
    "    print(summaries[0]['response'])\n",
    "else:\n",
    "    for summary in summaries:\n",
    "        print(f\"URL: {summary['url']}\")\n",
    "        print(f\"Code: {summary['code']}\")\n",
    "        print(f\"Summary: {summary['summary']}\")\n",
    "        print(\"-\" * 80)  # Separator for clarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
